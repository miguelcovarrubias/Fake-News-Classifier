{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classification using Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/fake-news-header.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "\n",
    "The way Fake News Classification is done at https://www.datacamp.com/community/tutorials/scikit-learn-fake-news is through training a model that uses a dataset produced by George McIntire.\n",
    "\n",
    "George McIntire's Dataset contains over 10,000 entries with the following information:\n",
    "\n",
    "```\n",
    "-title\n",
    "-text\n",
    "-label\n",
    "```\n",
    "\n",
    "Note: There are an even amount of 'FAKE' and 'REAL' news articles to prevent having a skewed dataset\n",
    "\n",
    "\n",
    "The following is an example entry from his dataset\n",
    "\n",
    "```\n",
    "title:\n",
    "Nearly All Wild Animals Face Mass Extinction By 2020\n",
    "\n",
    "\n",
    "text:\n",
    "Sean Adl-Tabatabai in News , World // 0 Comments \n",
    "A disturbing new report suggests that over two-thirds of wild animals living on Earth are set to become extinct by the year 2020. \n",
    "The comprehensive report by the WWF and Zoological Society of London says animal populations across the globe will continue to plummet by 67% by 2020 due to a mass extinction that is killing the natural world. \n",
    "Thegaurdian.com reports: \n",
    "...\n",
    "(article text truncated)\n",
    "\n",
    "\n",
    "label:\n",
    "FAKE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features\n",
    "\n",
    "We'll be using a Bag of Words approach for classification using the article's ```text```. \n",
    "\n",
    "We'll need to extract the features that we'll use to train the model by using some of the Vectorizer's in ```CountVectorizer```, ```TfidfVectorizer``` or ```HashingVectorizer```\n",
    "\n",
    "\n",
    "The following is an example of how the Vectorizer's would vectorize the ```text```\n",
    "![bag-of-words](images/bag-of-words.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing the Model\n",
    "                               \n",
    "The Vectorizer is used on the entire dataset to extract the features and more or less this is what our ```X``` and `y` will look like.\n",
    "\n",
    "![x_y](images/full-dataset.jpg)\n",
    "\n",
    "\n",
    "\n",
    "This would be an example of ```X_test``` and ```y_test```. We feed this into the classifier for fitting/training\n",
    "![x_y_train](images/training-dataset.jpg)\n",
    "\n",
    "\n",
    "\n",
    "This would be an example of ```X_test``` and ```y_test```. We feed the ```X_test`` into the classifier for predicting\n",
    "![x_y_test](images/testing-dataset.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
